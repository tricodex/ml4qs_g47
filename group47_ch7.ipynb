{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                                                            #\n",
    "#    Mark Hoogendoorn and Burkhardt Funk (2017)              #\n",
    "#    Machine Learning for the Quantified Self                #\n",
    "#    Springer                                                #\n",
    "#    Chapter 7                                               #\n",
    "#                                                            #\n",
    "##############################################################\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Chapter7.PrepareDatasetForLearning import PrepareDatasetForLearning\n",
    "from Chapter7.LearningAlgorithms import ClassificationAlgorithms\n",
    "from Chapter7.LearningAlgorithms import RegressionAlgorithms\n",
    "from Chapter7.Evaluation import ClassificationEvaluation\n",
    "from Chapter7.Evaluation import RegressionEvaluation\n",
    "from Chapter7.FeatureSelection import FeatureSelectionClassification\n",
    "from Chapter7.FeatureSelection import FeatureSelectionRegression\n",
    "from util import util\n",
    "from util.VisualizeDataset import VisualizeDataset\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:  (3623, 163)\n",
      "Dataset is not empty.\n",
      "Shape of the dataset:  (3623, 163)\n",
      "Class counts:  2    692\n",
      "3    683\n",
      "4    675\n",
      "0    565\n",
      "5    515\n",
      "1    493\n",
      "Name: cluster, dtype: int64\n",
      "Least populated class:  1\n",
      "Counts for labelCycling:  0    2915\n",
      "1     708\n",
      "Name: labelCycling, dtype: int64\n",
      "Counts for labelStairs:  0    3413\n",
      "1     210\n",
      "Name: labelStairs, dtype: int64\n",
      "Counts for labelWalking:  0    2984\n",
      "1     639\n",
      "Name: labelWalking, dtype: int64\n",
      "Counts for labelSitting:  1    1929\n",
      "0    1694\n",
      "Name: labelSitting, dtype: int64\n",
      "Counts for labelOther:  0    3474\n",
      "1     149\n",
      "Name: labelOther, dtype: int64\n",
      "Features:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162]\n",
      "Class label indices:  [9, 10, 11, 12, 13]\n",
      "Stratified sampling not possible due to one of the classes having less than 2 instances. Using simple random sampling instead.\n",
      "train_y is in the correct format.\n",
      "test_y is in the correct format.\n",
      "Shape of train_X:  (2525, 158)\n",
      "Shape of train_y:  (2525, 5)\n",
      "Shape of test_x:  (1083, 158)\n",
      "Shape of test_y:  (1083, 5)\n",
      "Shape of train_y values:  (12625,)\n",
      "First 10 values of train_y:  [0 0 1 0 0 1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "# Read the result from the previous chapter, and make sure the index is of the type datetime.\n",
    "DATA_PATH = Path('./datasets/group47/dataset/intermediate_datafiles/')\n",
    "DATASET_FNAME = 'chapter5_group47_result.csv'\n",
    "RESULT_FNAME = 'chapter7_group47_classification_result.csv'\n",
    "EXPORT_TREE_PATH = Path('./figures/crowdsignals_ch7_group47_classification/')\n",
    "\n",
    "# Next, we declare the parameters we'll use in the algorithms.\n",
    "N_FORWARD_SELECTION = 50\n",
    "\n",
    "try:\n",
    "    dataset = pd.read_csv(DATA_PATH / DATASET_FNAME, index_col=0)\n",
    "except IOError as e:\n",
    "    print('File not found, try to run previous crowdsignals scripts first!')\n",
    "    raise e\n",
    "\n",
    "dataset.index = pd.to_datetime(dataset.index)\n",
    "\n",
    "# Let us create our visualization class again.\n",
    "DataViz = VisualizeDataset()#__file__)\n",
    "\n",
    "# Let us consider our first task, namely the prediction of the label. We consider this as a non-temporal task.\n",
    "\n",
    "# We create a single column with the categorical attribute representing our class. Furthermore, we use 70% of our data\n",
    "# for training and the remaining 30% as an independent test set. We select the sets based on stratified sampling. We remove\n",
    "# cases where we do not know the label.\n",
    "\n",
    "prepare = PrepareDatasetForLearning()\n",
    "\n",
    "# Check if your dataset is empty\n",
    "print(\"Shape of the dataset: \", dataset.shape)\n",
    "\n",
    "# Check if your dataset is empty\n",
    "if dataset.empty:\n",
    "    print(\"Dataset is empty.\")\n",
    "else:\n",
    "    print(\"Dataset is not empty.\")\n",
    "\n",
    "# Check the shape of your dataset\n",
    "print(\"Shape of the dataset: \", dataset.shape)\n",
    "\n",
    "# Check the number of instances in each class\n",
    "class_counts = dataset['cluster'].value_counts()\n",
    "print(\"Class counts: \", class_counts)\n",
    "\n",
    "# Identify the least populated class\n",
    "least_populated_class = class_counts.idxmin()\n",
    "print(\"Least populated class: \", least_populated_class)\n",
    "\n",
    "# Check if the least populated class has less than 2 members\n",
    "if class_counts.min() < 2:\n",
    "    print(f\"The class '{least_populated_class}' has only {class_counts.min()} member, which is too few. The minimum number of groups for any class cannot be less than 2.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now, try the split\n",
    "try:\n",
    "    labels = ['labelCycling', 'labelStairs', 'labelWalking', 'labelSitting', 'labelOther']\n",
    "    # Check the number of instances for each label\n",
    "    for label in labels:\n",
    "        label_counts = dataset[label].value_counts()\n",
    "        print(f\"Counts for {label}: \", label_counts)\n",
    "\n",
    "    # binary_labels = mlb.fit_transform(dataset[labels])\n",
    "    # dataset[labels] = binary_labels\n",
    "    \n",
    "\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = prepare.split_single_dataset_classification(dataset, labels, 'cluster', 0.7, filter=True, temporal=False)\n",
    "\n",
    "    # Check if labels are in the correct format\n",
    "    def check_label_format(y):\n",
    "        unique_values = np.unique(y)\n",
    "        if len(unique_values) > 2 or not all(i in [0, 1] for i in unique_values):\n",
    "            print(\"Error: Labels are not in binary format.\")\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    # Check the format of train_y and test_y\n",
    "    if not check_label_format(train_y):\n",
    "        print(\"train_y is not in the correct format.\")\n",
    "        exit()\n",
    "    else:\n",
    "        print(\"train_y is in the correct format.\")\n",
    "\n",
    "    if not check_label_format(test_y):\n",
    "        print(\"test_y is not in the correct format.\")\n",
    "        exit()\n",
    "    else:\n",
    "        print(\"test_y is in the correct format.\")\n",
    "\n",
    "    print(\"Shape of train_X: \", train_X.shape)\n",
    "    print(\"Shape of train_y: \", train_y.shape)\n",
    "    print(\"Shape of test_x: \",test_X.shape)\n",
    "    print(\"Shape of test_y: \", test_y.shape)\n",
    "    print(\"Shape of train_y values: \", train_y.values.ravel().shape)\n",
    "    print(\"First 10 values of train_y: \", train_y.values.ravel()[:10])\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "\n",
    "    # Fit the LabelBinarizer and transform the labels\n",
    "    train_y = lb.fit_transform(train_y)\n",
    "    test_y = lb.transform(test_y)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(\"Error during split: \", str(e))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length is:  2525\n",
      "Test set length is:  1083\n",
      "#basic features:  16\n",
      "#PCA features:  7\n",
      "#time features:  32\n",
      "#frequency features:  81\n",
      "#cluster features:  1\n"
     ]
    }
   ],
   "source": [
    "print('Training set length is: ', len(train_X.index))\n",
    "print('Test set length is: ', len(test_X.index))\n",
    "\n",
    "# Select subsets of the features that we will consider:\n",
    "\n",
    "basic_features = ['acc_phone_x','acc_phone_y','acc_phone_z','lin_acc_phone_x','lin_acc_phone_y','lin_acc_phone_z','mag_phone_x','mag_phone_y','mag_phone_z','pca_1','pca_2','pca_3','pca_4','pca_5','pca_6','pca_7']\n",
    "pca_features = ['pca_1','pca_2','pca_3','pca_4','pca_5','pca_6','pca_7']\n",
    "time_features = [name for name in dataset.columns if '_temp_' in name]\n",
    "freq_features = [name for name in dataset.columns if (('_freq' in name) or ('_pse' in name))]\n",
    "print('#basic features: ', len(basic_features))\n",
    "print('#PCA features: ', len(pca_features))\n",
    "print('#time features: ', len(time_features))\n",
    "print('#frequency features: ', len(freq_features))\n",
    "cluster_features = ['cluster']\n",
    "print('#cluster features: ', len(cluster_features))\n",
    "features_after_chapter_3 = list(set().union(basic_features, pca_features))\n",
    "features_after_chapter_4 = list(set().union(basic_features, pca_features, time_features, freq_features))\n",
    "features_after_chapter_5 = list(set().union(basic_features, pca_features, time_features, freq_features, cluster_features))\n",
    "\n",
    "\n",
    "selected_features = {'chapter_3': features_after_chapter_3,\n",
    "                        'chapter_4': features_after_chapter_4,\n",
    "                        'chapter_5': features_after_chapter_5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added feature0\n",
      "Added feature1\n",
      "Added feature2\n",
      "Added feature3\n",
      "Added feature4\n",
      "Added feature5\n",
      "Added feature6\n",
      "Added feature7\n",
      "Added feature8\n",
      "Added feature9\n",
      "Added feature10\n",
      "Added feature11\n",
      "Added feature12\n",
      "Added feature13\n",
      "Added feature14\n",
      "Added feature15\n",
      "Added feature16\n",
      "Added feature17\n",
      "Added feature18\n",
      "Added feature19\n",
      "Added feature20\n",
      "Added feature21\n",
      "Added feature22\n",
      "Added feature23\n",
      "Added feature24\n",
      "Added feature25\n",
      "Added feature26\n",
      "Added feature27\n",
      "Added feature28\n",
      "Added feature29\n",
      "Added feature30\n",
      "Added feature31\n",
      "Added feature32\n",
      "Added feature33\n",
      "Added feature34\n",
      "Added feature35\n",
      "Added feature36\n",
      "Added feature37\n",
      "Added feature38\n",
      "Added feature39\n",
      "Added feature40\n",
      "Added feature41\n",
      "Added feature42\n",
      "Added feature43\n",
      "Added feature44\n",
      "Added feature45\n",
      "Added feature46\n",
      "Added feature47\n",
      "Added feature48\n",
      "Added feature49\n"
     ]
    }
   ],
   "source": [
    "# First, let us consider the performance over a selection of features:\n",
    "\n",
    "fs = FeatureSelectionClassification()\n",
    "\n",
    "features, ordered_features, ordered_scores = fs.forward_selection(N_FORWARD_SELECTION,\n",
    "                                                                  train_X[selected_features['chapter_5']],\n",
    "                                                                  test_X[selected_features['chapter_5']],\n",
    "                                                                  train_y,\n",
    "                                                                  test_y,\n",
    "                                                                  gridsearch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataViz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DataViz\u001b[39m.\u001b[39mplot_xy(x\u001b[39m=\u001b[39m[\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, N_FORWARD_SELECTION\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)], y\u001b[39m=\u001b[39m[ordered_scores],\n\u001b[0;32m      2\u001b[0m                 xlabel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumber of features\u001b[39m\u001b[39m'\u001b[39m, ylabel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataViz' is not defined"
     ]
    }
   ],
   "source": [
    "DataViz.plot_xy(x=[range(1, N_FORWARD_SELECTION+1)], y=[ordered_scores],\n",
    "                xlabel='number of features', ylabel='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first study the impact of regularization and model complexity: does regularization prevent overfitting?\n",
    "\n",
    "learner = ClassificationAlgorithms()\n",
    "eval = ClassificationEvaluation()\n",
    "start = time.time()\n",
    "\n",
    "reg_parameters = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "performance_training = []\n",
    "performance_test = []\n",
    "N_REPEATS_NN = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reg_param in reg_parameters:\n",
    "    performance_tr = 0\n",
    "    performance_te = 0\n",
    "    for i in range(0, N_REPEATS_NN):\n",
    "\n",
    "        class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.feedforward_neural_network(\n",
    "            train_X, train_y,\n",
    "            test_X, hidden_layer_sizes=(250, ), alpha=reg_param, max_iter=500,\n",
    "            gridsearch=False\n",
    "        )\n",
    "\n",
    "        performance_tr += eval.accuracy(train_y, class_train_y)\n",
    "        performance_te += eval.accuracy(test_y, class_test_y)\n",
    "    performance_training.append(performance_tr/N_REPEATS_NN)\n",
    "    performance_test.append(performance_te/N_REPEATS_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataViz.plot_xy(x=[reg_parameters, reg_parameters], y=[performance_training, performance_test], method='semilogx',\n",
    "                xlabel='regularization parameter value', ylabel='accuracy', ylim=[0.95, 1.01],\n",
    "                names=['training', 'test'], line_styles=['r-', 'b:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'min_samples_leaf': 2}\n",
      "Feature importance decision tree:\n",
      "mag_phone_y_temp_mean_ws_30 & 0.5198219934700646\n",
      "pca_3_temp_mean_ws_30 & 0.08658929130040623\n",
      "pca_1_temp_mean_ws_30 & 0.07847455011848531\n",
      "acc_phone_y_temp_mean_ws_30 & 0.04940059371595363\n",
      "acc_phone_y_temp_std_ws_30 & 0.04298300033071299\n",
      "mag_phone_y_temp_std_ws_30 & 0.03428718681449926\n",
      "pca_7_temp_std_ws_30 & 0.03170752296206501\n",
      "acc_phone_z_freq_0.0_Hz_ws_10 & 0.027213952399858674\n",
      "mag_phone_y & 0.025184148913247318\n",
      "acc_phone_z_temp_mean_ws_30 & 0.021640190222891983\n",
      "mag_phone_x & 0.02160720758548066\n",
      "mag_phone_x_freq_0.0_Hz_ws_10 & 0.014983737684304301\n",
      "acc_phone_x_freq_0.0_Hz_ws_10 & 0.013709057374630454\n",
      "mag_phone_y_max_freq & 0.01193296072398955\n",
      "pca_6_temp_std_ws_30 & 0.011140815261354485\n",
      "pca_4_temp_mean_ws_30 & 0.00932379112205554\n",
      "lin_acc_phone_y_freq_weighted & 0.0\n",
      "lin_acc_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.4_Hz_ws_10 & 0.0\n",
      "acc_phone_y_freq_weighted & 0.0\n",
      "mag_phone_x_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_z_pse & 0.0\n",
      "acc_phone_y_max_freq & 0.0\n",
      "acc_phone_x_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_z_temp_std_ws_30 & 0.0\n",
      "mag_phone_x_freq_weighted & 0.0\n",
      "acc_phone_x_temp_std_ws_30 & 0.0\n",
      "cluster & 0.0\n",
      "mag_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "pca_5 & 0.0\n",
      "acc_phone_y_pse & 0.0\n",
      "lin_acc_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_x_pse & 0.0\n",
      "acc_phone_z_freq_weighted & 0.0\n",
      "lin_acc_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_z_max_freq & 0.0\n",
      "mag_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "acc_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_1 & 0.0\n",
      "mag_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "pca_3 & 0.0\n",
      "lin_acc_phone_x_freq_weighted & 0.0\n",
      "lin_acc_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_z_max_freq & 0.0\n",
      "pca_6 & 0.0\n",
      "acc_phone_z_temp_std_ws_30 & 0.0\n",
      "mag_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_pse & 0.0\n",
      "mag_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "pca_4 & 0.0\n",
      "mag_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_max_freq & 0.0\n",
      "lin_acc_phone_z_freq_0.0_Hz_ws_10 & 0.0\n",
      "pca_7_temp_mean_ws_30 & 0.0\n",
      "mag_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "mag_phone_z_freq_0.0_Hz_ws_10 & 0.0\n",
      "mag_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z & 0.0\n",
      "acc_phone_x_max_freq & 0.0\n",
      "acc_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_freq_weighted & 0.0\n",
      "acc_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_z_pse & 0.0\n",
      "mag_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_x_max_freq & 0.0\n",
      "acc_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_freq_0.0_Hz_ws_10 & 0.0\n",
      "pca_2_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_temp_std_ws_30 & 0.0\n",
      "lin_acc_phone_y_max_freq & 0.0\n",
      "acc_phone_x & 0.0\n",
      "lin_acc_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_pse & 0.0\n",
      "acc_phone_x_pse & 0.0\n",
      "lin_acc_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_y_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_y & 0.0\n",
      "pca_5_temp_mean_ws_30 & 0.0\n",
      "acc_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_2 & 0.0\n",
      "mag_phone_y_pse & 0.0\n",
      "lin_acc_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "pca_5_temp_std_ws_30 & 0.0\n",
      "pca_7 & 0.0\n",
      "lin_acc_phone_x_pse & 0.0\n",
      "acc_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "pca_3_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.4_Hz_ws_10 & 0.0\n",
      "acc_phone_z & 0.0\n",
      "acc_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_temp_mean_ws_30 & 0.0\n",
      "pca_2_temp_mean_ws_30 & 0.0\n",
      "pca_4_temp_std_ws_30 & 0.0\n",
      "mag_phone_y_freq_weighted & 0.0\n",
      "lin_acc_phone_y & 0.0\n",
      "mag_phone_x_temp_std_ws_30 & 0.0\n",
      "lin_acc_phone_x_max_freq & 0.0\n",
      "mag_phone_z_temp_std_ws_30 & 0.0\n",
      "mag_phone_z_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_y_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_x & 0.0\n",
      "lin_acc_phone_y_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_1_temp_std_ws_30 & 0.0\n",
      "mag_phone_z_freq_weighted & 0.0\n",
      "pca_6_temp_mean_ws_30 & 0.0\n",
      "acc_phone_x_freq_weighted & 0.0\n",
      "lin_acc_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "mag_phone_z & 0.0\n",
      "export_tree_path: figures\\crowdsignals_ch7_group47_classification\n",
      "export_tree_name: tree.dot\n",
      "Type of train_X.columns: <class 'pandas.core.indexes.base.Index'>\n",
      "Type of dtree.classes_: <class 'numpy.ndarray'>\n",
      "Unique class labels: [0 1]\n",
      "Types of class labels: [<class 'numpy.int32'>, <class 'numpy.int32'>]\n",
      "Unique values in train_y: [0 1]\n",
      "Shape of train_y: (2525, 5)\n",
      "Unique values in class_train_y: [0 1]\n",
      "Shape of class_train_y: (2525,)\n",
      "{'criterion': 'gini', 'min_samples_leaf': 2}\n",
      "Feature importance decision tree:\n",
      "mag_phone_y_temp_mean_ws_30 & 0.4506574696427588\n",
      "pca_1_temp_mean_ws_30 & 0.15648545126694804\n",
      "acc_phone_y_temp_mean_ws_30 & 0.08476842266535407\n",
      "pca_7_temp_std_ws_30 & 0.048622562380728276\n",
      "acc_phone_z_temp_std_ws_30 & 0.04124115833120399\n",
      "acc_phone_z_freq_0.0_Hz_ws_10 & 0.028793826907604233\n",
      "acc_phone_x_pse & 0.02346163673952938\n",
      "mag_phone_y_freq_0.4_Hz_ws_10 & 0.02026058380616808\n",
      "pca_3_temp_mean_ws_30 & 0.019286827700865646\n",
      "mag_phone_z_freq_0.3_Hz_ws_10 & 0.018655094527171418\n",
      "pca_2_temp_std_ws_30 & 0.01737899017742917\n",
      "mag_phone_x_freq_0.0_Hz_ws_10 & 0.0167583119568067\n",
      "mag_phone_z_temp_std_ws_30 & 0.01564109115968625\n",
      "mag_phone_y_freq_0.0_Hz_ws_10 & 0.014389818296538823\n",
      "lin_acc_phone_y & 0.013034242633071876\n",
      "lin_acc_phone_z_temp_std_ws_30 & 0.007244712496263922\n",
      "mag_phone_y & 0.006416136483764463\n",
      "lin_acc_phone_y_freq_0.4_Hz_ws_10 & 0.004858237912208794\n",
      "acc_phone_x_freq_0.3_Hz_ws_10 & 0.004849829019239954\n",
      "lin_acc_phone_z_freq_weighted & 0.0047728329641689585\n",
      "lin_acc_phone_z_freq_0.2_Hz_ws_10 & 0.002422762932489154\n",
      "lin_acc_phone_y_freq_weighted & 0.0\n",
      "lin_acc_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "acc_phone_y_freq_weighted & 0.0\n",
      "mag_phone_x_temp_mean_ws_30 & 0.0\n",
      "acc_phone_y_temp_std_ws_30 & 0.0\n",
      "lin_acc_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_x & 0.0\n",
      "mag_phone_z_pse & 0.0\n",
      "acc_phone_y_max_freq & 0.0\n",
      "acc_phone_x_temp_mean_ws_30 & 0.0\n",
      "mag_phone_x_freq_weighted & 0.0\n",
      "acc_phone_x_temp_std_ws_30 & 0.0\n",
      "cluster & 0.0\n",
      "mag_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "pca_5 & 0.0\n",
      "acc_phone_y_pse & 0.0\n",
      "lin_acc_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_x_pse & 0.0\n",
      "acc_phone_z_freq_weighted & 0.0\n",
      "lin_acc_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_z_max_freq & 0.0\n",
      "mag_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "mag_phone_y_max_freq & 0.0\n",
      "acc_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_1 & 0.0\n",
      "mag_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "pca_3 & 0.0\n",
      "lin_acc_phone_x_freq_weighted & 0.0\n",
      "lin_acc_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_z_max_freq & 0.0\n",
      "pca_6 & 0.0\n",
      "mag_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_pse & 0.0\n",
      "mag_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "pca_4 & 0.0\n",
      "mag_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_max_freq & 0.0\n",
      "lin_acc_phone_z_freq_0.0_Hz_ws_10 & 0.0\n",
      "pca_7_temp_mean_ws_30 & 0.0\n",
      "mag_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "mag_phone_z_freq_0.0_Hz_ws_10 & 0.0\n",
      "mag_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_y_temp_std_ws_30 & 0.0\n",
      "lin_acc_phone_z & 0.0\n",
      "acc_phone_x_max_freq & 0.0\n",
      "acc_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "acc_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_z_pse & 0.0\n",
      "mag_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_x_max_freq & 0.0\n",
      "acc_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_freq_0.0_Hz_ws_10 & 0.0\n",
      "acc_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_temp_std_ws_30 & 0.0\n",
      "lin_acc_phone_y_max_freq & 0.0\n",
      "acc_phone_x & 0.0\n",
      "lin_acc_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_pse & 0.0\n",
      "lin_acc_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_temp_mean_ws_30 & 0.0\n",
      "mag_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_y & 0.0\n",
      "pca_5_temp_mean_ws_30 & 0.0\n",
      "acc_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "pca_4_temp_mean_ws_30 & 0.0\n",
      "mag_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_2 & 0.0\n",
      "mag_phone_y_pse & 0.0\n",
      "pca_6_temp_std_ws_30 & 0.0\n",
      "acc_phone_x_freq_0.0_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "pca_5_temp_std_ws_30 & 0.0\n",
      "pca_7 & 0.0\n",
      "lin_acc_phone_x_pse & 0.0\n",
      "acc_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "pca_3_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.4_Hz_ws_10 & 0.0\n",
      "acc_phone_z & 0.0\n",
      "acc_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "mag_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_temp_mean_ws_30 & 0.0\n",
      "pca_2_temp_mean_ws_30 & 0.0\n",
      "pca_4_temp_std_ws_30 & 0.0\n",
      "mag_phone_y_freq_weighted & 0.0\n",
      "mag_phone_x_temp_std_ws_30 & 0.0\n",
      "lin_acc_phone_x_max_freq & 0.0\n",
      "mag_phone_z_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_y_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_x & 0.0\n",
      "lin_acc_phone_y_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_1_temp_std_ws_30 & 0.0\n",
      "acc_phone_z_temp_mean_ws_30 & 0.0\n",
      "mag_phone_z_freq_weighted & 0.0\n",
      "pca_6_temp_mean_ws_30 & 0.0\n",
      "acc_phone_x_freq_weighted & 0.0\n",
      "lin_acc_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "mag_phone_z & 0.0\n",
      "export_tree_path: figures\\crowdsignals_ch7_group47_classification\n",
      "export_tree_name: tree.dot\n",
      "Type of train_X.columns: <class 'pandas.core.indexes.base.Index'>\n",
      "Type of dtree.classes_: <class 'numpy.ndarray'>\n",
      "Unique class labels: [0 1]\n",
      "Types of class labels: [<class 'numpy.int32'>, <class 'numpy.int32'>]\n",
      "Unique values in train_y: [0 1]\n",
      "Shape of train_y: (2525, 5)\n",
      "Unique values in class_train_y: [0 1]\n",
      "Shape of class_train_y: (2525,)\n",
      "{'criterion': 'entropy', 'min_samples_leaf': 2}\n",
      "Feature importance decision tree:\n",
      "mag_phone_y_temp_mean_ws_30 & 0.5198219934700646\n",
      "pca_3_temp_mean_ws_30 & 0.08658929130040623\n",
      "pca_1_temp_mean_ws_30 & 0.07847455011848531\n",
      "acc_phone_y_temp_mean_ws_30 & 0.04940059371595363\n",
      "acc_phone_y_temp_std_ws_30 & 0.04298300033071299\n",
      "mag_phone_y_temp_std_ws_30 & 0.03428718681449926\n",
      "pca_7_temp_std_ws_30 & 0.03170752296206501\n",
      "acc_phone_z_freq_0.0_Hz_ws_10 & 0.027213952399858674\n",
      "mag_phone_y & 0.025184148913247318\n",
      "pca_2_temp_mean_ws_30 & 0.024849872635984937\n",
      "acc_phone_z_temp_mean_ws_30 & 0.021640190222891983\n",
      "mag_phone_x & 0.02160720758548066\n",
      "lin_acc_phone_x_freq_0.0_Hz_ws_10 & 0.014983737684304301\n",
      "mag_phone_y_max_freq & 0.01193296072398955\n",
      "pca_4_temp_mean_ws_30 & 0.00932379112205554\n",
      "lin_acc_phone_y_freq_weighted & 0.0\n",
      "lin_acc_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.4_Hz_ws_10 & 0.0\n",
      "acc_phone_y_freq_weighted & 0.0\n",
      "mag_phone_x_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_z_pse & 0.0\n",
      "acc_phone_y_max_freq & 0.0\n",
      "acc_phone_x_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_z_temp_std_ws_30 & 0.0\n",
      "mag_phone_x_freq_weighted & 0.0\n",
      "acc_phone_x_temp_std_ws_30 & 0.0\n",
      "cluster & 0.0\n",
      "mag_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "pca_5 & 0.0\n",
      "acc_phone_y_pse & 0.0\n",
      "lin_acc_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_x_pse & 0.0\n",
      "acc_phone_z_freq_weighted & 0.0\n",
      "lin_acc_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_z_max_freq & 0.0\n",
      "mag_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "acc_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_1 & 0.0\n",
      "mag_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "pca_3 & 0.0\n",
      "lin_acc_phone_x_freq_weighted & 0.0\n",
      "lin_acc_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_z_max_freq & 0.0\n",
      "pca_6 & 0.0\n",
      "acc_phone_z_temp_std_ws_30 & 0.0\n",
      "mag_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_pse & 0.0\n",
      "mag_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "pca_4 & 0.0\n",
      "mag_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_max_freq & 0.0\n",
      "lin_acc_phone_z_freq_0.0_Hz_ws_10 & 0.0\n",
      "pca_7_temp_mean_ws_30 & 0.0\n",
      "mag_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "mag_phone_z_freq_0.0_Hz_ws_10 & 0.0\n",
      "mag_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z & 0.0\n",
      "acc_phone_x_max_freq & 0.0\n",
      "acc_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_freq_weighted & 0.0\n",
      "acc_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_z_pse & 0.0\n",
      "mag_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_x_max_freq & 0.0\n",
      "acc_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "pca_2_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_temp_std_ws_30 & 0.0\n",
      "lin_acc_phone_y_max_freq & 0.0\n",
      "acc_phone_x & 0.0\n",
      "lin_acc_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_pse & 0.0\n",
      "acc_phone_x_pse & 0.0\n",
      "lin_acc_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_y_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_y & 0.0\n",
      "pca_5_temp_mean_ws_30 & 0.0\n",
      "acc_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_2 & 0.0\n",
      "mag_phone_y_pse & 0.0\n",
      "pca_6_temp_std_ws_30 & 0.0\n",
      "acc_phone_x_freq_0.0_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "pca_5_temp_std_ws_30 & 0.0\n",
      "pca_7 & 0.0\n",
      "lin_acc_phone_x_pse & 0.0\n",
      "acc_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "pca_3_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.4_Hz_ws_10 & 0.0\n",
      "acc_phone_z & 0.0\n",
      "acc_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "mag_phone_x_freq_0.0_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_temp_mean_ws_30 & 0.0\n",
      "pca_4_temp_std_ws_30 & 0.0\n",
      "mag_phone_y_freq_weighted & 0.0\n",
      "lin_acc_phone_y & 0.0\n",
      "mag_phone_x_temp_std_ws_30 & 0.0\n",
      "lin_acc_phone_x_max_freq & 0.0\n",
      "mag_phone_z_temp_std_ws_30 & 0.0\n",
      "mag_phone_z_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_y_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_x & 0.0\n",
      "lin_acc_phone_y_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_1_temp_std_ws_30 & 0.0\n",
      "mag_phone_z_freq_weighted & 0.0\n",
      "pca_6_temp_mean_ws_30 & 0.0\n",
      "acc_phone_x_freq_weighted & 0.0\n",
      "lin_acc_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "mag_phone_z & 0.0\n",
      "export_tree_path: figures\\crowdsignals_ch7_group47_classification\n",
      "export_tree_name: tree.dot\n",
      "Type of train_X.columns: <class 'pandas.core.indexes.base.Index'>\n",
      "Type of dtree.classes_: <class 'numpy.ndarray'>\n",
      "Unique class labels: [0 1]\n",
      "Types of class labels: [<class 'numpy.int32'>, <class 'numpy.int32'>]\n",
      "Unique values in train_y: [0 1]\n",
      "Shape of train_y: (2525, 5)\n",
      "Unique values in class_train_y: [0 1]\n",
      "Shape of class_train_y: (2525,)\n",
      "{'criterion': 'entropy', 'min_samples_leaf': 2}\n",
      "Feature importance decision tree:\n",
      "mag_phone_y_temp_mean_ws_30 & 0.5198219934700646\n",
      "pca_3_temp_mean_ws_30 & 0.10338693184705272\n",
      "pca_1_temp_mean_ws_30 & 0.07847455011848531\n",
      "acc_phone_y_temp_mean_ws_30 & 0.04940059371595363\n",
      "pca_7_temp_std_ws_30 & 0.04364048368605456\n",
      "mag_phone_y & 0.04016788659755162\n",
      "mag_phone_y_temp_std_ws_30 & 0.03428718681449926\n",
      "acc_phone_z_freq_0.0_Hz_ws_10 & 0.027213952399858674\n",
      "acc_phone_y_temp_std_ws_30 & 0.026185359784066494\n",
      "acc_phone_z_temp_mean_ws_30 & 0.021640190222891983\n",
      "mag_phone_x & 0.02160720758548066\n",
      "pca_2_temp_mean_ws_30 & 0.013709057374630454\n",
      "lin_acc_phone_y_freq_0.5_Hz_ws_10 & 0.011140815261354485\n",
      "pca_5_temp_std_ws_30 & 0.00932379112205554\n",
      "lin_acc_phone_y_freq_weighted & 0.0\n",
      "lin_acc_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.4_Hz_ws_10 & 0.0\n",
      "acc_phone_y_freq_weighted & 0.0\n",
      "mag_phone_x_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_z_pse & 0.0\n",
      "acc_phone_y_max_freq & 0.0\n",
      "acc_phone_x_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_z_temp_std_ws_30 & 0.0\n",
      "mag_phone_x_freq_weighted & 0.0\n",
      "acc_phone_x_temp_std_ws_30 & 0.0\n",
      "cluster & 0.0\n",
      "mag_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "pca_5 & 0.0\n",
      "acc_phone_y_pse & 0.0\n",
      "lin_acc_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_x_pse & 0.0\n",
      "acc_phone_z_freq_weighted & 0.0\n",
      "lin_acc_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_z_max_freq & 0.0\n",
      "mag_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "mag_phone_y_max_freq & 0.0\n",
      "acc_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_z_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_1 & 0.0\n",
      "mag_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "pca_3 & 0.0\n",
      "lin_acc_phone_x_freq_weighted & 0.0\n",
      "lin_acc_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_z_max_freq & 0.0\n",
      "pca_6 & 0.0\n",
      "acc_phone_z_temp_std_ws_30 & 0.0\n",
      "mag_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_pse & 0.0\n",
      "mag_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "pca_4 & 0.0\n",
      "mag_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_max_freq & 0.0\n",
      "lin_acc_phone_z_freq_0.0_Hz_ws_10 & 0.0\n",
      "pca_7_temp_mean_ws_30 & 0.0\n",
      "mag_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "mag_phone_z_freq_0.0_Hz_ws_10 & 0.0\n",
      "mag_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z & 0.0\n",
      "acc_phone_x_max_freq & 0.0\n",
      "acc_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_freq_weighted & 0.0\n",
      "acc_phone_y_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_z_pse & 0.0\n",
      "mag_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_x_max_freq & 0.0\n",
      "acc_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.5_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_freq_0.0_Hz_ws_10 & 0.0\n",
      "pca_2_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_temp_std_ws_30 & 0.0\n",
      "lin_acc_phone_y_max_freq & 0.0\n",
      "acc_phone_x & 0.0\n",
      "lin_acc_phone_x_freq_0.4_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_pse & 0.0\n",
      "acc_phone_x_pse & 0.0\n",
      "lin_acc_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "acc_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_z_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_y_freq_0.4_Hz_ws_10 & 0.0\n",
      "mag_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "acc_phone_y & 0.0\n",
      "pca_5_temp_mean_ws_30 & 0.0\n",
      "acc_phone_z_freq_0.5_Hz_ws_10 & 0.0\n",
      "pca_4_temp_mean_ws_30 & 0.0\n",
      "mag_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_2 & 0.0\n",
      "mag_phone_y_pse & 0.0\n",
      "pca_6_temp_std_ws_30 & 0.0\n",
      "acc_phone_x_freq_0.0_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_y_freq_0.1_Hz_ws_10 & 0.0\n",
      "pca_7 & 0.0\n",
      "lin_acc_phone_x_pse & 0.0\n",
      "acc_phone_y_freq_0.0_Hz_ws_10 & 0.0\n",
      "pca_3_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.4_Hz_ws_10 & 0.0\n",
      "acc_phone_z & 0.0\n",
      "acc_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "mag_phone_x_freq_0.0_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.3_Hz_ws_10 & 0.0\n",
      "mag_phone_z_freq_0.2_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_temp_mean_ws_30 & 0.0\n",
      "pca_4_temp_std_ws_30 & 0.0\n",
      "mag_phone_y_freq_weighted & 0.0\n",
      "lin_acc_phone_y & 0.0\n",
      "mag_phone_x_temp_std_ws_30 & 0.0\n",
      "lin_acc_phone_x_max_freq & 0.0\n",
      "mag_phone_z_temp_std_ws_30 & 0.0\n",
      "mag_phone_z_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_y_temp_mean_ws_30 & 0.0\n",
      "lin_acc_phone_x & 0.0\n",
      "lin_acc_phone_y_temp_std_ws_30 & 0.0\n",
      "acc_phone_y_freq_0.3_Hz_ws_10 & 0.0\n",
      "pca_1_temp_std_ws_30 & 0.0\n",
      "mag_phone_z_freq_weighted & 0.0\n",
      "pca_6_temp_mean_ws_30 & 0.0\n",
      "acc_phone_x_freq_weighted & 0.0\n",
      "lin_acc_phone_z_freq_0.1_Hz_ws_10 & 0.0\n",
      "lin_acc_phone_x_freq_0.2_Hz_ws_10 & 0.0\n",
      "acc_phone_x_freq_0.1_Hz_ws_10 & 0.0\n",
      "mag_phone_z & 0.0\n",
      "export_tree_path: figures\\crowdsignals_ch7_group47_classification\n",
      "export_tree_name: tree.dot\n",
      "Type of train_X.columns: <class 'pandas.core.indexes.base.Index'>\n",
      "Type of dtree.classes_: <class 'numpy.ndarray'>\n",
      "Unique class labels: [0 1]\n",
      "Types of class labels: [<class 'numpy.int32'>, <class 'numpy.int32'>]\n",
      "Unique values in train_y: [0 1]\n",
      "Shape of train_y: (2525, 5)\n",
      "Unique values in class_train_y: [0 1]\n",
      "Shape of class_train_y: (2525,)\n"
     ]
    }
   ],
   "source": [
    "# Second, let us consider the influence of certain parameter settings for the tree model.\n",
    "\n",
    "leaf_settings = [1,2,5,10]\n",
    "performance_training = []\n",
    "performance_test = []\n",
    "\n",
    "# Convert train_y to a DataFrame\n",
    "train_y_df = pd.DataFrame(train_y, columns=['labelCycling', 'labelStairs', 'labelWalking', 'labelSitting', 'labelOther'])\n",
    "\n",
    "for no_points_leaf in leaf_settings:\n",
    "\n",
    "    # class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.decision_tree(\n",
    "    #     train_X[selected_features['chapter_5']], train_y, test_X[selected_features['chapter_5']], min_samples_leaf=no_points_leaf,\n",
    "    #     gridsearch=False, print_model_details=False)\n",
    "\n",
    "    # Then pass train_y_df to the decision_tree method\n",
    "    class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.decision_tree(\n",
    "        train_X[selected_features['chapter_5']], train_y_df, test_X[selected_features['chapter_5']],\n",
    "        gridsearch=True,\n",
    "        print_model_details=True, export_tree_path=EXPORT_TREE_PATH)\n",
    "\n",
    "    # performance_training.append(eval.accuracy(train_y, class_train_y))\n",
    "    #new\n",
    "    print(\"Unique values in train_y:\", np.unique(train_y))\n",
    "    print(\"Shape of train_y:\", train_y.shape)\n",
    "\n",
    "    print(\"Unique values in class_train_y:\", np.unique(class_train_y))\n",
    "    print(\"Shape of class_train_y:\", class_train_y.shape)\n",
    "    #performance_training.append(jaccard_score(train_y, class_train_y, average='samples'))\n",
    "    mlb = MultiLabelBinarizer(classes=np.unique(train_y))\n",
    "    #class_train_y_binarized = mlb.fit_transform(class_train_y.reshape(-1, 1))\n",
    "    # Create an empty binary matrix with the same shape as train_y\n",
    "    class_train_y_binarized = np.zeros_like(train_y)\n",
    "\n",
    "    # Set the corresponding columns in class_train_y_binarized to 1 based on the labels in class_train_y\n",
    "    for i, label in enumerate(class_train_y):\n",
    "        class_train_y_binarized[i, label] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_y:  (2525, 5)\n",
      "Shape of class_train_y_binarized:  (2525, 5)\n",
      "Unique labels in class_train_y:  [0 1]\n",
      "Shape of test_y:  (1083, 5)\n",
      "Shape of class_test_y_binarized:  (1083, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_y: \", train_y.shape)\n",
    "print(\"Shape of class_train_y_binarized: \", class_train_y_binarized.shape)\n",
    "print(\"Unique labels in class_train_y: \", np.unique(class_train_y))\n",
    "print(\"Shape of test_y: \", test_y.shape)\n",
    "print(\"Shape of class_test_y_binarized: \", class_test_y_binarized.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "inconsistent shapes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m mlb \u001b[39m=\u001b[39m MultiLabelBinarizer()\n\u001b[0;32m      4\u001b[0m class_test_y_binarized \u001b[39m=\u001b[39m mlb\u001b[39m.\u001b[39mfit_transform(class_test_y\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m performance_test\u001b[39m.\u001b[39mappend(\u001b[39meval\u001b[39;49m\u001b[39m.\u001b[39;49maccuracy(test_y, class_test_y_binarized))\n",
      "File \u001b[1;32mc:\\Users\\patri\\Desktop\\University\\AI\\ml4qs\\code\\ml4qs_47\\Chapter7\\Evaluation.py:21\u001b[0m, in \u001b[0;36mClassificationEvaluation.accuracy\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maccuracy\u001b[39m(\u001b[39mself\u001b[39m, y_true, y_pred):\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m metrics\u001b[39m.\u001b[39;49maccuracy_score(y_true, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:188\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    186\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 188\u001b[0m     differing_labels \u001b[39m=\u001b[39m count_nonzero(y_true \u001b[39m-\u001b[39;49m y_pred, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    189\u001b[0m     score \u001b[39m=\u001b[39m differing_labels \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\scipy\\sparse\\base.py:437\u001b[0m, in \u001b[0;36mspmatrix.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[39melif\u001b[39;00m isspmatrix(other):\n\u001b[0;32m    436\u001b[0m     \u001b[39mif\u001b[39;00m other\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape:\n\u001b[1;32m--> 437\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minconsistent shapes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sub_sparse(other)\n\u001b[0;32m    439\u001b[0m \u001b[39melif\u001b[39;00m isdense(other):\n",
      "\u001b[1;31mValueError\u001b[0m: inconsistent shapes"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "class_test_y_binarized = mlb.fit_transform(class_test_y.reshape(-1, 1))\n",
    "\n",
    "performance_test.append(eval.accuracy(test_y, class_test_y_binarized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m performance_training\u001b[39m.\u001b[39mappend(jaccard_score(train_y, class_train_y_binarized, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m performance_test\u001b[39m.\u001b[39mappend(\u001b[39meval\u001b[39;49m\u001b[39m.\u001b[39;49maccuracy(test_y, class_test_y))\n",
      "File \u001b[1;32mc:\\Users\\patri\\Desktop\\University\\AI\\ml4qs\\code\\ml4qs_47\\Chapter7\\Evaluation.py:21\u001b[0m, in \u001b[0;36mClassificationEvaluation.accuracy\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maccuracy\u001b[39m(\u001b[39mself\u001b[39m, y_true, y_pred):\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m metrics\u001b[39m.\u001b[39;49maccuracy_score(y_true, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:185\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    186\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:89\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     86\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mand \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(type_true, type_pred))\n\u001b[0;32m     92\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m     93\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "performance_training.append(jaccard_score(train_y, class_train_y_binarized, average='samples'))\n",
    "\n",
    "performance_test.append(eval.accuracy(test_y, class_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataViz.plot_xy(x=[leaf_settings, leaf_settings], y=[performance_training, performance_test],\n",
    "                xlabel='minimum number of points per leaf', ylabel='accuracy',\n",
    "                names=['training', 'test'], line_styles=['r-', 'b:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing took 1787.6657936573029 seconds.\n"
     ]
    }
   ],
   "source": [
    "# So yes, it is important :) Therefore we perform grid searches over the most important parameters, and do so by means\n",
    "# of cross validation upon the training set.\n",
    "\n",
    "possible_feature_sets = [basic_features] + list(selected_features.values())\n",
    "feature_names = ['initial set'] + list(selected_features.keys())\n",
    "N_KCV_REPEATS = 5\n",
    "\n",
    "print('Preprocessing took', time.time()-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NeuralNetwork run 0 / 5 ... \n",
      "Training RandomForest run 0 / 5 ... \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m performance_tr_nn \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39maccuracy(train_y, class_train_y)\n\u001b[0;32m     23\u001b[0m performance_te_nn \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39maccuracy(test_y, class_test_y)\n\u001b[1;32m---> 25\u001b[0m class_train_y, class_test_y, class_train_prob_y, class_test_prob_y \u001b[39m=\u001b[39m learner\u001b[39m.\u001b[39;49mrandom_forest(\n\u001b[0;32m     26\u001b[0m     selected_train_X, train_y, selected_test_X, gridsearch\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m performance_tr_rf \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39maccuracy(train_y, class_train_y)\n\u001b[0;32m     30\u001b[0m performance_te_rf \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39maccuracy(test_y, class_test_y)\n",
      "File \u001b[1;32mc:\\Users\\patri\\Desktop\\University\\AI\\ml4qs\\code\\ml4qs_47\\Chapter7\\LearningAlgorithms.py:296\u001b[0m, in \u001b[0;36mClassificationAlgorithms.random_forest\u001b[1;34m(self, train_X, train_y, test_X, n_estimators, min_samples_leaf, criterion, print_model_details, gridsearch)\u001b[0m\n\u001b[0;32m    292\u001b[0m     rf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39mn_estimators, min_samples_leaf\u001b[39m=\u001b[39mmin_samples_leaf, criterion\u001b[39m=\u001b[39mcriterion)\n\u001b[0;32m    294\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m rf\u001b[39m.\u001b[39mfit(train_X, train_y\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39mravel())\n\u001b[0;32m    298\u001b[0m \u001b[39mif\u001b[39;00m gridsearch \u001b[39mand\u001b[39;00m print_model_details:\n\u001b[0;32m    299\u001b[0m     \u001b[39mprint\u001b[39m(rf\u001b[39m.\u001b[39mbest_params_)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "scores_over_all_algs = []\n",
    "\n",
    "for i in range(0, len(possible_feature_sets)):\n",
    "    selected_train_X = train_X[possible_feature_sets[i]]\n",
    "    selected_test_X = test_X[possible_feature_sets[i]]\n",
    "\n",
    "    # First we run our non deterministic classifiers a number of times to average their score.\n",
    "\n",
    "    performance_tr_nn = 0\n",
    "    performance_tr_rf = 0\n",
    "    performance_tr_svm = 0\n",
    "    performance_te_nn = 0\n",
    "    performance_te_rf = 0\n",
    "    performance_te_svm = 0\n",
    "\n",
    "    for repeat in range(0, N_KCV_REPEATS):\n",
    "        print(\"Training NeuralNetwork run {} / {} ... \".format(repeat, N_KCV_REPEATS, feature_names[i]))\n",
    "        class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.feedforward_neural_network(\n",
    "            selected_train_X, train_y, selected_test_X, gridsearch=True\n",
    "        )\n",
    "        print(\"Training RandomForest run {} / {} ... \".format(repeat, N_KCV_REPEATS, feature_names[i]))\n",
    "        performance_tr_nn += eval.accuracy(train_y, class_train_y)\n",
    "        performance_te_nn += eval.accuracy(test_y, class_test_y)\n",
    "        \n",
    "        class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.random_forest(\n",
    "            selected_train_X, train_y, selected_test_X, gridsearch=True\n",
    "        )\n",
    "        \n",
    "        performance_tr_rf += eval.accuracy(train_y, class_train_y)\n",
    "        performance_te_rf += eval.accuracy(test_y, class_test_y)\n",
    "\n",
    "        print(\"Training SVM run {} / {}, featureset: {}... \".format(repeat, N_KCV_REPEATS, feature_names[i]))\n",
    "      \n",
    "        class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.support_vector_machine_with_kernel(\n",
    "            selected_train_X, train_y, selected_test_X, gridsearch=True\n",
    "        )\n",
    "        performance_tr_svm += eval.accuracy(train_y, class_train_y)\n",
    "        performance_te_svm += eval.accuracy(test_y, class_test_y)\n",
    "\n",
    "    overall_performance_tr_nn = performance_tr_nn/N_KCV_REPEATS\n",
    "    overall_performance_te_nn = performance_te_nn/N_KCV_REPEATS\n",
    "    overall_performance_tr_rf = performance_tr_rf/N_KCV_REPEATS\n",
    "    overall_performance_te_rf = performance_te_rf/N_KCV_REPEATS\n",
    "    overall_performance_tr_svm = performance_tr_svm/N_KCV_REPEATS\n",
    "    overall_performance_te_svm = performance_te_svm/N_KCV_REPEATS\n",
    "\n",
    "    #     #And we run our deterministic classifiers:\n",
    "    print(\"Determenistic Classifiers:\")\n",
    "\n",
    "    print(\"Training Nearest Neighbor run 1 / 1, featureset {}:\".format(feature_names[i]))\n",
    "    class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.k_nearest_neighbor(\n",
    "        selected_train_X, train_y, selected_test_X, gridsearch=True\n",
    "    )\n",
    "    performance_tr_knn = eval.accuracy(train_y, class_train_y)\n",
    "    performance_te_knn = eval.accuracy(test_y, class_test_y)\n",
    "    print(\"Training Descision Tree run 1 / 1  featureset {}:\".format(feature_names[i]))\n",
    "    class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.decision_tree(\n",
    "        selected_train_X, train_y, selected_test_X, gridsearch=True\n",
    "    )\n",
    "    \n",
    "    performance_tr_dt = eval.accuracy(train_y, class_train_y)\n",
    "    performance_te_dt = eval.accuracy(test_y, class_test_y)\n",
    "    print(\"Training Naive Bayes run 1/1 featureset {}:\".format(feature_names[i]))\n",
    "    class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.naive_bayes(\n",
    "        selected_train_X, train_y, selected_test_X\n",
    "    )\n",
    "   \n",
    "    performance_tr_nb = eval.accuracy(train_y, class_train_y)\n",
    "    performance_te_nb = eval.accuracy(test_y, class_test_y)\n",
    "\n",
    "    scores_with_sd = util.print_table_row_performances(feature_names[i], len(selected_train_X.index), len(selected_test_X.index), [\n",
    "                                                                                                (overall_performance_tr_nn, overall_performance_te_nn),\n",
    "                                                                                                (overall_performance_tr_rf, overall_performance_te_rf),\n",
    "                                                                                                (overall_performance_tr_svm, overall_performance_te_svm),\n",
    "                                                                                                (performance_tr_knn, performance_te_knn),\n",
    "                                                                                                (performance_tr_dt, performance_te_dt),\n",
    "                                                                                                (performance_tr_nb, performance_te_nb)])\n",
    "    scores_over_all_algs.append(scores_with_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataViz.plot_performances_classification(['NN', 'RF','SVM', 'KNN', 'DT', 'NB'], feature_names, scores_over_all_algs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # And we study two promising ones in more detail. First, let us consider the decision tree, which works best with the\n",
    "# # selected features.\n",
    "\n",
    "class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.decision_tree(train_X[selected_features], train_y, test_X[selected_features],\n",
    "                                                                                           gridsearch=True,\n",
    "                                                                                           print_model_details=True, export_tree_path=EXPORT_TREE_PATH)\n",
    "\n",
    "class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.random_forest(\n",
    "    train_X[selected_features], train_y, test_X[selected_features],\n",
    "    gridsearch=True, print_model_details=True)\n",
    "\n",
    "test_cm = eval.confusion_matrix(test_y, class_test_y, class_train_prob_y.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataViz.plot_confusion_matrix(test_cm, class_train_prob_y.columns, normalize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4qs_p3_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
