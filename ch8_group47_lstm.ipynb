{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_path = './datasets/group47/dataset/intermediate_datafiles/chapter5_group47_result.csv'\n",
    "try:\n",
    "    data = pd.read_csv(data_path, index_col=0)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at {data_path}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target columns\n",
    "target_columns = ['labelCycling', 'labelStairs', 'labelWalking', 'labelSitting', 'labelOther']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and target variables\n",
    "X = data.drop(target_columns, axis=1)\n",
    "y = data[target_columns]\n",
    "\n",
    "# Fill NaN values with 0 (or any other value you deem appropriate)\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Replace positive infinity values with the maximum non-infinity number\n",
    "X = X.replace([np.inf], np.finfo('float64').max)\n",
    "\n",
    "# Replace negative infinity values with the minimum non-infinity number\n",
    "X = X.replace([-np.inf], np.finfo('float64').min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: UserWarning: Features [48 96] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: UserWarning: Features [49 54 96] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: UserWarning: Features [50 55 60 65 96] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: UserWarning: Features [51 56 61 66 71 96] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: UserWarning: Features [52 57 62 67 72 96] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "selected_features = set()\n",
    "for column in y.columns:\n",
    "    y_single_label = LabelEncoder().fit_transform(y[column])  # Convert to 1D array\n",
    "    selector = SelectKBest(f_classif, k=50)\n",
    "    X_new = selector.fit_transform(X, y_single_label)\n",
    "    \n",
    "    # Get the selected features for this label\n",
    "    mask = selector.get_support()  # List of booleans for selected features\n",
    "    selected_features_single_label = X.columns[mask]\n",
    "    \n",
    "    # Add the selected features for this label to the set of all selected features\n",
    "    selected_features.update(selected_features_single_label)\n",
    "\n",
    "# Filter the features based on the selected features\n",
    "X = X[list(selected_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    " # Use simple random sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, input_shape=(X_train.shape[1], 1)))  # Increase the number of units\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(200, return_sequences=True))  # Add another LSTM layer\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))  # Keep this LSTM layer\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(len(target_columns), activation='sigmoid'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])  # Use learning_rate instead of lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 3s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predictions to binary format\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "labelCycling       0.24      0.66      0.35       247\n",
      " labelStairs       0.09      0.09      0.09        64\n",
      "labelWalking       0.09      0.04      0.06       192\n",
      "labelSitting       0.64      0.52      0.58       649\n",
      "  labelOther       0.00      0.00      0.00        50\n",
      "\n",
      "   micro avg       0.34      0.43      0.38      1202\n",
      "   macro avg       0.21      0.26      0.21      1202\n",
      "weighted avg       0.42      0.43      0.40      1202\n",
      " samples avg       0.34      0.43      0.36      1202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_bin, target_names=target_columns))\n",
    "precision = precision_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4163865660747246\n",
      "Recall: 0.42678868552412647\n",
      "F1 Score: 0.39620574487846194\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your classifier\n",
    "clf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Wrap your classifier with OneVsRestClassifier\n",
    "clf = OneVsRestClassifier(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your parameter grid\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_features': ['sqrt', 'log2'],\n",
    "    'estimator__max_depth' : [4,5,6,7,8],\n",
    "    'estimator__criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                                            ccp_alpha=0.0,\n",
       "                                                                            class_weight='balanced',\n",
       "                                                                            criterion='gini',\n",
       "                                                                            max_depth=None,\n",
       "                                                                            max_features='auto',\n",
       "                                                                            max_leaf_nodes=None,\n",
       "                                                                            max_samples=None,\n",
       "                                                                            min_impurity_decrease=0.0,\n",
       "                                                                            min_impurity_split=None,\n",
       "                                                                            min_samples_leaf=1,\n",
       "                                                                            min_samples_split=2,\n",
       "                                                                            min_weight_fraction_le...\n",
       "                                                                            oob_score=False,\n",
       "                                                                            random_state=42,\n",
       "                                                                            verbose=0,\n",
       "                                                                            warm_start=False),\n",
       "                                           n_jobs=None),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'estimator__criterion': ['gini', 'entropy'],\n",
       "                         'estimator__max_depth': [4, 5, 6, 7, 8],\n",
       "                         'estimator__max_features': ['sqrt', 'log2'],\n",
       "                         'estimator__n_estimators': [50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize GridSearchCV with F1 score as the scoring metric\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1_macro')  # Use F1 score\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'estimator__criterion': 'entropy', 'estimator__max_depth': 4, 'estimator__max_features': 'log2', 'estimator__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "61/61 [==============================] - 15s 191ms/step - loss: 0.4196 - accuracy: 0.5477 - val_loss: 0.3631 - val_accuracy: 0.5700\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 11s 182ms/step - loss: 0.3658 - accuracy: 0.5770 - val_loss: 0.3532 - val_accuracy: 0.6008\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 11s 184ms/step - loss: 0.3550 - accuracy: 0.5884 - val_loss: 0.3200 - val_accuracy: 0.6893\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 11s 179ms/step - loss: 0.2947 - accuracy: 0.7105 - val_loss: 0.2558 - val_accuracy: 0.7737\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 11s 180ms/step - loss: 0.2449 - accuracy: 0.7599 - val_loss: 0.2278 - val_accuracy: 0.7737\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 11s 181ms/step - loss: 0.2419 - accuracy: 0.7414 - val_loss: 0.2273 - val_accuracy: 0.7510\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 11s 179ms/step - loss: 0.2429 - accuracy: 0.7110 - val_loss: 0.2260 - val_accuracy: 0.7469\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 11s 181ms/step - loss: 0.2347 - accuracy: 0.7146 - val_loss: 0.2275 - val_accuracy: 0.7058\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 11s 183ms/step - loss: 0.2328 - accuracy: 0.7038 - val_loss: 0.2140 - val_accuracy: 0.7058\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 11s 182ms/step - loss: 0.2083 - accuracy: 0.7635 - val_loss: 0.1903 - val_accuracy: 0.7881\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 11s 186ms/step - loss: 0.2281 - accuracy: 0.7192 - val_loss: 0.2347 - val_accuracy: 0.7058\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 11s 185ms/step - loss: 0.2451 - accuracy: 0.7244 - val_loss: 0.2320 - val_accuracy: 0.7551\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 11s 185ms/step - loss: 0.2265 - accuracy: 0.7501 - val_loss: 0.2187 - val_accuracy: 0.7551\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 12s 189ms/step - loss: 0.2171 - accuracy: 0.7527 - val_loss: 0.1916 - val_accuracy: 0.7551\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 12s 189ms/step - loss: 0.1724 - accuracy: 0.7986 - val_loss: 0.1207 - val_accuracy: 0.8971\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 0.1332 - accuracy: 0.8640 - val_loss: 0.1192 - val_accuracy: 0.8971\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 11s 182ms/step - loss: 0.1001 - accuracy: 0.9073 - val_loss: 0.0950 - val_accuracy: 0.9115\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 11s 182ms/step - loss: 0.0811 - accuracy: 0.9356 - val_loss: 0.0531 - val_accuracy: 0.9527\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 11s 188ms/step - loss: 0.0670 - accuracy: 0.9454 - val_loss: 0.0402 - val_accuracy: 0.9691\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 11s 189ms/step - loss: 0.0677 - accuracy: 0.9428 - val_loss: 0.0302 - val_accuracy: 0.9774\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 0.0618 - accuracy: 0.9490 - val_loss: 0.0331 - val_accuracy: 0.9712\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 11s 184ms/step - loss: 0.0470 - accuracy: 0.9660 - val_loss: 0.0271 - val_accuracy: 0.9794\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 11s 184ms/step - loss: 0.0438 - accuracy: 0.9675 - val_loss: 0.0195 - val_accuracy: 0.9794\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 11s 185ms/step - loss: 0.0361 - accuracy: 0.9711 - val_loss: 0.0169 - val_accuracy: 0.9877\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 0.0351 - accuracy: 0.9727 - val_loss: 0.0104 - val_accuracy: 0.9938\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 11s 186ms/step - loss: 0.0258 - accuracy: 0.9845 - val_loss: 0.0251 - val_accuracy: 0.9815\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 0.0290 - accuracy: 0.9815 - val_loss: 0.0160 - val_accuracy: 0.9918\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 11s 184ms/step - loss: 0.0248 - accuracy: 0.9815 - val_loss: 0.0088 - val_accuracy: 0.9979\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 11s 181ms/step - loss: 0.0207 - accuracy: 0.9851 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 0.0208 - accuracy: 0.9871 - val_loss: 0.0132 - val_accuracy: 0.9959\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 12s 190ms/step - loss: 0.0253 - accuracy: 0.9815 - val_loss: 0.0085 - val_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 12s 193ms/step - loss: 0.0191 - accuracy: 0.9861 - val_loss: 0.0092 - val_accuracy: 0.9959\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 11s 186ms/step - loss: 0.0179 - accuracy: 0.9876 - val_loss: 0.0086 - val_accuracy: 0.9959\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 11s 185ms/step - loss: 0.0155 - accuracy: 0.9902 - val_loss: 0.0148 - val_accuracy: 0.9918\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 11s 186ms/step - loss: 0.0213 - accuracy: 0.9866 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 0.0108 - accuracy: 0.9918 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 12s 192ms/step - loss: 0.0150 - accuracy: 0.9887 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 12s 190ms/step - loss: 0.0133 - accuracy: 0.9907 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 12s 191ms/step - loss: 0.0147 - accuracy: 0.9907 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 11s 188ms/step - loss: 0.0126 - accuracy: 0.9897 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 12s 190ms/step - loss: 0.0080 - accuracy: 0.9954 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 11s 188ms/step - loss: 0.0115 - accuracy: 0.9933 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 12s 190ms/step - loss: 0.0107 - accuracy: 0.9954 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 11s 189ms/step - loss: 0.0080 - accuracy: 0.9959 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 11s 188ms/step - loss: 0.0107 - accuracy: 0.9933 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 11s 189ms/step - loss: 0.0096 - accuracy: 0.9943 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 0.0100 - accuracy: 0.9948 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 11s 185ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 12s 189ms/step - loss: 0.0131 - accuracy: 0.9892 - val_loss: 0.0151 - val_accuracy: 0.9835\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 12s 201ms/step - loss: 0.0154 - accuracy: 0.9912 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "38/38 [==============================] - 2s 46ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "labelCycling       1.00      1.00      1.00       247\n",
      " labelStairs       1.00      0.94      0.97        64\n",
      "labelWalking       1.00      0.98      0.99       192\n",
      "labelSitting       1.00      1.00      1.00       649\n",
      "  labelOther       0.93      1.00      0.96        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1202\n",
      "   macro avg       0.98      0.98      0.98      1202\n",
      "weighted avg       1.00      0.99      0.99      1202\n",
      " samples avg       1.00      0.99      0.99      1202\n",
      "\n",
      "Precision: 0.9952573820460677\n",
      "Recall: 0.9925124792013311\n",
      "F1 Score: 0.9937541672634966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, input_shape=(X_train.shape[1], 1)))  # Add dropout and recurrent dropout\n",
    "model.add(LSTM(100, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))  # Reduce the number of units and add dropout and recurrent dropout\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(len(target_columns), activation='sigmoid')) \n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])  # Use learning_rate instead of lr\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)  # Stop training when the validation loss has not improved for 10 epochs\n",
    "\n",
    "# Fit the model with the training data\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=30, callbacks=[early_stopping])  # Add validation split and early stopping\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predictions to binary format\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_bin, target_names=target_columns))\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "61/61 [==============================] - 14s 179ms/step - loss: 0.4832 - accuracy: 0.4894 - val_loss: 0.4041 - val_accuracy: 0.5288\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 12s 198ms/step - loss: 0.3985 - accuracy: 0.5183 - val_loss: 0.3718 - val_accuracy: 0.5288\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 12s 199ms/step - loss: 0.3836 - accuracy: 0.5188 - val_loss: 0.3659 - val_accuracy: 0.5288\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 13s 206ms/step - loss: 0.3707 - accuracy: 0.5245 - val_loss: 0.3481 - val_accuracy: 0.5288\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 12s 203ms/step - loss: 0.3378 - accuracy: 0.5873 - val_loss: 0.2983 - val_accuracy: 0.7058\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 13s 207ms/step - loss: 0.2799 - accuracy: 0.7043 - val_loss: 0.2461 - val_accuracy: 0.7058\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 13s 213ms/step - loss: 0.2495 - accuracy: 0.7038 - val_loss: 0.2341 - val_accuracy: 0.7058\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 14s 223ms/step - loss: 0.2404 - accuracy: 0.7063 - val_loss: 0.2270 - val_accuracy: 0.7058\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.2447 - accuracy: 0.7146 - val_loss: 0.2231 - val_accuracy: 0.7058\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 15s 240ms/step - loss: 0.2389 - accuracy: 0.7058 - val_loss: 0.2159 - val_accuracy: 0.7058\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.2270 - accuracy: 0.7316 - val_loss: 0.2105 - val_accuracy: 0.7346\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 14s 222ms/step - loss: 0.2182 - accuracy: 0.7558 - val_loss: 0.1891 - val_accuracy: 0.7984\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 13s 219ms/step - loss: 0.2024 - accuracy: 0.7640 - val_loss: 0.1978 - val_accuracy: 0.7922\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 14s 235ms/step - loss: 0.2209 - accuracy: 0.7697 - val_loss: 0.1984 - val_accuracy: 0.7716\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 15s 250ms/step - loss: 0.1906 - accuracy: 0.7955 - val_loss: 0.1551 - val_accuracy: 0.8004\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 14s 234ms/step - loss: 0.1773 - accuracy: 0.7970 - val_loss: 0.1649 - val_accuracy: 0.7922\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 14s 222ms/step - loss: 0.1657 - accuracy: 0.8264 - val_loss: 0.1603 - val_accuracy: 0.8313\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 16s 258ms/step - loss: 0.1605 - accuracy: 0.8346 - val_loss: 0.1552 - val_accuracy: 0.8560\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 14s 225ms/step - loss: 0.1497 - accuracy: 0.8511 - val_loss: 0.1236 - val_accuracy: 0.8827\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.1350 - accuracy: 0.8660 - val_loss: 0.1047 - val_accuracy: 0.9280\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 14s 224ms/step - loss: 0.1319 - accuracy: 0.8712 - val_loss: 0.0918 - val_accuracy: 0.9239\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 14s 235ms/step - loss: 0.1303 - accuracy: 0.8810 - val_loss: 0.0806 - val_accuracy: 0.9321\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0922 - accuracy: 0.9279 - val_loss: 0.0649 - val_accuracy: 0.9444\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 13s 218ms/step - loss: 0.0738 - accuracy: 0.9464 - val_loss: 0.0507 - val_accuracy: 0.9547\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 14s 223ms/step - loss: 0.0555 - accuracy: 0.9547 - val_loss: 0.0292 - val_accuracy: 0.9753\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 14s 222ms/step - loss: 0.0582 - accuracy: 0.9500 - val_loss: 0.0355 - val_accuracy: 0.9733\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0379 - accuracy: 0.9737 - val_loss: 0.0221 - val_accuracy: 0.9815\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0301 - accuracy: 0.9815 - val_loss: 0.0151 - val_accuracy: 0.9918\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 14s 222ms/step - loss: 0.0316 - accuracy: 0.9748 - val_loss: 0.0113 - val_accuracy: 0.9979\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 13s 219ms/step - loss: 0.0233 - accuracy: 0.9856 - val_loss: 0.0121 - val_accuracy: 0.9959\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 14s 232ms/step - loss: 0.0200 - accuracy: 0.9861 - val_loss: 0.0084 - val_accuracy: 0.9959\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 14s 225ms/step - loss: 0.0324 - accuracy: 0.9763 - val_loss: 0.0109 - val_accuracy: 0.9918\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 14s 228ms/step - loss: 0.0244 - accuracy: 0.9835 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 13s 221ms/step - loss: 0.0133 - accuracy: 0.9938 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 13s 221ms/step - loss: 0.0185 - accuracy: 0.9871 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 14s 224ms/step - loss: 0.0134 - accuracy: 0.9933 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 14s 223ms/step - loss: 0.0124 - accuracy: 0.9923 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 14s 223ms/step - loss: 0.0175 - accuracy: 0.9882 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 14s 222ms/step - loss: 0.0143 - accuracy: 0.9907 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 14s 223ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0103 - accuracy: 0.9948 - val_loss: 0.0042 - val_accuracy: 0.9979\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 14s 230ms/step - loss: 0.0098 - accuracy: 0.9954 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 13s 217ms/step - loss: 0.0096 - accuracy: 0.9954 - val_loss: 0.0088 - val_accuracy: 0.9959\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 14s 233ms/step - loss: 0.0122 - accuracy: 0.9918 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 14s 238ms/step - loss: 0.0090 - accuracy: 0.9954 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 14s 233ms/step - loss: 0.0110 - accuracy: 0.9943 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 13s 218ms/step - loss: 0.0099 - accuracy: 0.9933 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 14s 224ms/step - loss: 0.0126 - accuracy: 0.9928 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 14s 222ms/step - loss: 0.0103 - accuracy: 0.9938 - val_loss: 0.0046 - val_accuracy: 0.9979\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 14s 227ms/step - loss: 0.0079 - accuracy: 0.9969 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 14s 226ms/step - loss: 0.0149 - accuracy: 0.9933 - val_loss: 0.0043 - val_accuracy: 0.9979\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 13s 220ms/step - loss: 0.0067 - accuracy: 0.9969 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 14s 222ms/step - loss: 0.0083 - accuracy: 0.9923 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 14s 224ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 14s 224ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 13s 221ms/step - loss: 0.0070 - accuracy: 0.9964 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 14s 234ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 14s 234ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 14s 234ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 14s 229ms/step - loss: 0.0081 - accuracy: 0.9938 - val_loss: 0.0056 - val_accuracy: 0.9979\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 14s 232ms/step - loss: 0.0085 - accuracy: 0.9943 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 14s 231ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 14s 225ms/step - loss: 0.0038 - accuracy: 0.9979 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 14s 224ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 15s 246ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 15s 240ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 14s 236ms/step - loss: 0.0080 - accuracy: 0.9964 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 14s 225ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 14s 224ms/step - loss: 0.0041 - accuracy: 0.9974 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 14s 223ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 14s 223ms/step - loss: 0.0053 - accuracy: 0.9969 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "38/38 [==============================] - 2s 51ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "labelCycling       1.00      1.00      1.00       247\n",
      " labelStairs       1.00      0.97      0.98        64\n",
      "labelWalking       1.00      0.98      0.99       192\n",
      "labelSitting       1.00      1.00      1.00       649\n",
      "  labelOther       1.00      0.96      0.98        50\n",
      "\n",
      "   micro avg       1.00      0.99      1.00      1202\n",
      "   macro avg       1.00      0.98      0.99      1202\n",
      "weighted avg       1.00      0.99      1.00      1202\n",
      " samples avg       1.00      0.99      1.00      1202\n",
      "\n",
      "Precision: 0.9983386663253553\n",
      "Recall: 0.9933444259567388\n",
      "F1 Score: 0.9958012167484614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, input_shape=(X_train.shape[1], 1)))  # Add dropout and recurrent dropout\n",
    "model.add(LSTM(100, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))  # Reduce the number of units and add dropout and recurrent dropout\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(len(target_columns), activation='sigmoid'))  # Change activation function to softmax\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])  # Use learning_rate instead of lr\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)  # Stop training when the validation loss has not improved for 10 epochs\n",
    "\n",
    "# Fit the model with the training data\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=100, callbacks=[early_stopping])  # Add validation split and early stopping\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predictions to binary format\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_bin, target_names=target_columns))\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "61/61 [==============================] - 15s 202ms/step - loss: 29.6736 - accuracy: 0.5157 - val_loss: 11.3701 - val_accuracy: 0.5288\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 11s 187ms/step - loss: 4.6537 - accuracy: 0.5265 - val_loss: 1.5864 - val_accuracy: 0.5288\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 12s 194ms/step - loss: 0.9383 - accuracy: 0.5265 - val_loss: 0.6113 - val_accuracy: 0.5288\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 12s 194ms/step - loss: 0.5767 - accuracy: 0.5265 - val_loss: 0.5516 - val_accuracy: 0.5288\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 12s 200ms/step - loss: 0.5381 - accuracy: 0.5265 - val_loss: 0.5243 - val_accuracy: 0.5288\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 12s 195ms/step - loss: 0.5270 - accuracy: 0.5265 - val_loss: 0.5239 - val_accuracy: 0.5288\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 12s 193ms/step - loss: 0.5278 - accuracy: 0.5265 - val_loss: 0.5277 - val_accuracy: 0.5288\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 12s 196ms/step - loss: 0.5300 - accuracy: 0.5265 - val_loss: 0.5270 - val_accuracy: 0.5288\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 12s 194ms/step - loss: 0.5267 - accuracy: 0.5265 - val_loss: 0.5289 - val_accuracy: 0.5288\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 12s 198ms/step - loss: 0.5262 - accuracy: 0.5265 - val_loss: 0.5261 - val_accuracy: 0.5288\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 0.5249 - accuracy: 0.5265 - val_loss: 0.5193 - val_accuracy: 0.5288\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 12s 198ms/step - loss: 0.5231 - accuracy: 0.5265 - val_loss: 0.5206 - val_accuracy: 0.5288\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 12s 200ms/step - loss: 0.5255 - accuracy: 0.5265 - val_loss: 0.5204 - val_accuracy: 0.5288\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 12s 201ms/step - loss: 0.5232 - accuracy: 0.5265 - val_loss: 0.5229 - val_accuracy: 0.5288\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 12s 205ms/step - loss: 0.5230 - accuracy: 0.5265 - val_loss: 0.5187 - val_accuracy: 0.5288\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 13s 208ms/step - loss: 0.5214 - accuracy: 0.5265 - val_loss: 0.5247 - val_accuracy: 0.5288\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 12s 201ms/step - loss: 0.5234 - accuracy: 0.5265 - val_loss: 0.5188 - val_accuracy: 0.5288\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 12s 199ms/step - loss: 0.5214 - accuracy: 0.5265 - val_loss: 0.5187 - val_accuracy: 0.5288\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 12s 196ms/step - loss: 0.5225 - accuracy: 0.5265 - val_loss: 0.5195 - val_accuracy: 0.5288\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 12s 196ms/step - loss: 0.5225 - accuracy: 0.5265 - val_loss: 0.5192 - val_accuracy: 0.5288\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 0.5231 - accuracy: 0.5265 - val_loss: 0.5206 - val_accuracy: 0.5288\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 12s 194ms/step - loss: 0.5239 - accuracy: 0.5265 - val_loss: 0.5198 - val_accuracy: 0.5288\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 12s 196ms/step - loss: 0.5225 - accuracy: 0.5265 - val_loss: 0.5215 - val_accuracy: 0.5288\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 0.5236 - accuracy: 0.5265 - val_loss: 0.5223 - val_accuracy: 0.5288\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 12s 199ms/step - loss: 0.5247 - accuracy: 0.5265 - val_loss: 0.5197 - val_accuracy: 0.5288\n",
      "38/38 [==============================] - 2s 54ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "labelCycling       0.00      0.00      0.00       247\n",
      " labelStairs       0.00      0.00      0.00        64\n",
      "labelWalking       0.00      0.00      0.00       192\n",
      "labelSitting       0.54      1.00      0.70       649\n",
      "  labelOther       0.00      0.00      0.00        50\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      1202\n",
      "   macro avg       0.11      0.20      0.14      1202\n",
      "weighted avg       0.29      0.54      0.38      1202\n",
      " samples avg       0.54      0.54      0.54      1202\n",
      "\n",
      "Precision: 0.7530571956438267\n",
      "Recall: 0.5399334442595674\n",
      "F1 Score: 0.3798556155278691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l1_l2\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, dropout=0.3, recurrent_dropout=0.3, \n",
    "               kernel_regularizer=l1_l2(l1=0.01, l2=0.01),  # Add L1/L2 regularization\n",
    "               input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(100, return_sequences=False, dropout=0.3, recurrent_dropout=0.3, \n",
    "               kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))  # Add L1/L2 regularization\n",
    "model.add(Dense(100, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))  # Add L1/L2 regularization\n",
    "model.add(Dense(len(target_columns), activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Fit the model with the training data\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=100, callbacks=[early_stopping])\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predictions to binary format\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_bin, target_names=target_columns))\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "labelCycling       1.00      1.00      1.00       247\n",
      " labelStairs       1.00      1.00      1.00        64\n",
      "labelWalking       1.00      1.00      1.00       192\n",
      "labelSitting       1.00      1.00      1.00       649\n",
      "  labelOther       1.00      1.00      1.00        50\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      1202\n",
      "   macro avg       1.00      1.00      1.00      1202\n",
      "weighted avg       1.00      1.00      1.00      1202\n",
      " samples avg       1.00      1.00      1.00      1202\n",
      "\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define your classifier with the best parameters\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=best_params['estimator__n_estimators'],\n",
    "    max_features=best_params['estimator__max_features'],\n",
    "    max_depth=best_params['estimator__max_depth'],\n",
    "    criterion=best_params['estimator__criterion'],\n",
    "    min_samples_split=10,  # Increase this value to add more regularization\n",
    "    min_samples_leaf=5,  # Increase this value to add more regularization\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Wrap your classifier with OneVsRestClassifier\n",
    "clf = OneVsRestClassifier(clf)\n",
    "\n",
    "# Fit the model with the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred, target_names=target_columns))\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "61/61 [==============================] - 29s 399ms/step - loss: 0.5518 - accuracy: 0.2164 - val_loss: 0.4937 - val_accuracy: 0.2181\n",
      "Epoch 2/30\n",
      "61/61 [==============================] - 24s 398ms/step - loss: 0.4600 - accuracy: 0.2303 - val_loss: 0.4038 - val_accuracy: 0.2551\n",
      "Epoch 3/30\n",
      "61/61 [==============================] - 25s 404ms/step - loss: 0.3753 - accuracy: 0.5064 - val_loss: 0.2937 - val_accuracy: 0.8498\n",
      "Epoch 4/30\n",
      "61/61 [==============================] - 25s 411ms/step - loss: 0.2815 - accuracy: 0.8027 - val_loss: 0.1744 - val_accuracy: 0.8848\n",
      "Epoch 5/30\n",
      "61/61 [==============================] - 24s 397ms/step - loss: 0.1736 - accuracy: 0.8434 - val_loss: 0.1102 - val_accuracy: 0.9074\n",
      "Epoch 6/30\n",
      "61/61 [==============================] - 25s 410ms/step - loss: 0.1308 - accuracy: 0.8697 - val_loss: 0.0949 - val_accuracy: 0.9218\n",
      "Epoch 7/30\n",
      "61/61 [==============================] - 26s 429ms/step - loss: 0.1188 - accuracy: 0.9037 - val_loss: 0.0750 - val_accuracy: 0.9444\n",
      "Epoch 8/30\n",
      "61/61 [==============================] - 25s 405ms/step - loss: 0.0935 - accuracy: 0.9263 - val_loss: 0.0808 - val_accuracy: 0.9259\n",
      "Epoch 9/30\n",
      "61/61 [==============================] - 25s 410ms/step - loss: 0.0985 - accuracy: 0.9155 - val_loss: 0.0622 - val_accuracy: 0.9424\n",
      "Epoch 10/30\n",
      "61/61 [==============================] - 25s 406ms/step - loss: 0.0752 - accuracy: 0.9382 - val_loss: 0.0530 - val_accuracy: 0.9486\n",
      "Epoch 11/30\n",
      "61/61 [==============================] - 26s 420ms/step - loss: 0.0649 - accuracy: 0.9469 - val_loss: 0.0499 - val_accuracy: 0.9527\n",
      "Epoch 12/30\n",
      "61/61 [==============================] - 26s 432ms/step - loss: 0.0619 - accuracy: 0.9464 - val_loss: 0.0469 - val_accuracy: 0.9588\n",
      "Epoch 13/30\n",
      "61/61 [==============================] - 26s 423ms/step - loss: 0.0703 - accuracy: 0.9382 - val_loss: 0.0395 - val_accuracy: 0.9712\n",
      "Epoch 14/30\n",
      "61/61 [==============================] - 25s 417ms/step - loss: 0.0458 - accuracy: 0.9650 - val_loss: 0.0368 - val_accuracy: 0.9712\n",
      "Epoch 15/30\n",
      "61/61 [==============================] - 29s 469ms/step - loss: 0.0541 - accuracy: 0.9552 - val_loss: 0.0349 - val_accuracy: 0.9650\n",
      "Epoch 16/30\n",
      "61/61 [==============================] - 26s 427ms/step - loss: 0.0427 - accuracy: 0.9681 - val_loss: 0.0282 - val_accuracy: 0.9774\n",
      "Epoch 17/30\n",
      "61/61 [==============================] - 26s 428ms/step - loss: 0.0373 - accuracy: 0.9701 - val_loss: 0.0309 - val_accuracy: 0.9630\n",
      "Epoch 18/30\n",
      "61/61 [==============================] - 26s 423ms/step - loss: 0.0401 - accuracy: 0.9650 - val_loss: 0.0301 - val_accuracy: 0.9774\n",
      "Epoch 19/30\n",
      "61/61 [==============================] - 25s 412ms/step - loss: 0.0412 - accuracy: 0.9717 - val_loss: 0.0177 - val_accuracy: 0.9877\n",
      "Epoch 20/30\n",
      "61/61 [==============================] - 25s 412ms/step - loss: 0.0374 - accuracy: 0.9717 - val_loss: 0.0132 - val_accuracy: 0.9938\n",
      "Epoch 21/30\n",
      "61/61 [==============================] - 25s 410ms/step - loss: 0.0367 - accuracy: 0.9701 - val_loss: 0.0191 - val_accuracy: 0.9794\n",
      "Epoch 22/30\n",
      "61/61 [==============================] - 25s 411ms/step - loss: 0.0277 - accuracy: 0.9830 - val_loss: 0.0177 - val_accuracy: 0.9877\n",
      "Epoch 23/30\n",
      "61/61 [==============================] - 25s 410ms/step - loss: 0.0377 - accuracy: 0.9681 - val_loss: 0.0190 - val_accuracy: 0.9897\n",
      "Epoch 24/30\n",
      "61/61 [==============================] - 25s 407ms/step - loss: 0.0286 - accuracy: 0.9768 - val_loss: 0.0166 - val_accuracy: 0.9877\n",
      "Epoch 25/30\n",
      "61/61 [==============================] - 25s 407ms/step - loss: 0.0271 - accuracy: 0.9804 - val_loss: 0.0184 - val_accuracy: 0.9815\n",
      "Epoch 26/30\n",
      "61/61 [==============================] - 25s 407ms/step - loss: 0.0258 - accuracy: 0.9768 - val_loss: 0.0201 - val_accuracy: 0.9794\n",
      "Epoch 27/30\n",
      "61/61 [==============================] - 25s 409ms/step - loss: 0.0237 - accuracy: 0.9815 - val_loss: 0.0138 - val_accuracy: 0.9938\n",
      "Epoch 28/30\n",
      "61/61 [==============================] - 25s 410ms/step - loss: 0.0212 - accuracy: 0.9820 - val_loss: 0.0103 - val_accuracy: 0.9918\n",
      "Epoch 29/30\n",
      "61/61 [==============================] - 25s 409ms/step - loss: 0.0220 - accuracy: 0.9815 - val_loss: 0.0100 - val_accuracy: 0.9938\n",
      "Epoch 30/30\n",
      "61/61 [==============================] - 25s 409ms/step - loss: 0.0201 - accuracy: 0.9830 - val_loss: 0.0184 - val_accuracy: 0.9815\n",
      "38/38 [==============================] - 5s 116ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "labelCycling       1.00      1.00      1.00       247\n",
      " labelStairs       0.98      0.94      0.96        64\n",
      "labelWalking       0.98      0.97      0.97       192\n",
      "labelSitting       1.00      0.99      0.99       649\n",
      "  labelOther       1.00      1.00      1.00        50\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1202\n",
      "   macro avg       0.99      0.98      0.99      1202\n",
      "weighted avg       0.99      0.99      0.99      1202\n",
      " samples avg       0.99      0.99      0.99      1202\n",
      "\n",
      "Precision: 0.9932646296001194\n",
      "Recall: 0.9883527454242929\n",
      "F1 Score: 0.9907746451368118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, input_shape=(X_train.shape[1], 1)))  # Add dropout and recurrent dropout\n",
    "model.add(LSTM(100, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))  # Reduce the number of units and add dropout and recurrent dropout\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(len(target_columns), activation='sigmoid'))  # Change activation function to softmax\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])  # Use learning_rate instead of lr\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)  # Stop training when the validation loss has not improved for 10 epochs\n",
    "\n",
    "# Fit the model with the training data\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=30, callbacks=[early_stopping])  # Add validation split and early stopping\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predictions to binary format\n",
    "y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_bin, target_names=target_columns))\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred_bin, average='weighted', zero_division=1)\n",
    "\n",
    "# Print precision, recall, and F1 score\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "61/61 [==============================] - 37s 509ms/step - loss: 0.4750 - accuracy: 0.5064 - val_loss: 0.4013 - val_accuracy: 0.5597\n",
      "Epoch 2/30\n",
      "61/61 [==============================] - 32s 528ms/step - loss: 0.4031 - accuracy: 0.5374 - val_loss: 0.3733 - val_accuracy: 0.5597\n",
      "Epoch 3/30\n",
      "61/61 [==============================] - 33s 542ms/step - loss: 0.3772 - accuracy: 0.5647 - val_loss: 0.3583 - val_accuracy: 0.5597\n",
      "Epoch 4/30\n",
      "61/61 [==============================] - 32s 522ms/step - loss: 0.3603 - accuracy: 0.6012 - val_loss: 0.3289 - val_accuracy: 0.6955\n",
      "Epoch 5/30\n",
      "61/61 [==============================] - 30s 498ms/step - loss: 0.3271 - accuracy: 0.6589 - val_loss: 0.2810 - val_accuracy: 0.7675\n",
      "Epoch 6/30\n",
      "61/61 [==============================] - 30s 496ms/step - loss: 0.2680 - accuracy: 0.7393 - val_loss: 0.2367 - val_accuracy: 0.7757\n",
      "Epoch 7/30\n",
      "61/61 [==============================] - 31s 500ms/step - loss: 0.2451 - accuracy: 0.7429 - val_loss: 0.2196 - val_accuracy: 0.7819\n",
      "Epoch 8/30\n",
      "61/61 [==============================] - 31s 511ms/step - loss: 0.2347 - accuracy: 0.7439 - val_loss: 0.2081 - val_accuracy: 0.7695\n",
      "Epoch 9/30\n",
      "61/61 [==============================] - 36s 584ms/step - loss: 0.2220 - accuracy: 0.7548 - val_loss: 0.1982 - val_accuracy: 0.8004\n",
      "Epoch 10/30\n",
      "61/61 [==============================] - 33s 544ms/step - loss: 0.2114 - accuracy: 0.7573 - val_loss: 0.1954 - val_accuracy: 0.7593\n",
      "Epoch 11/30\n",
      "61/61 [==============================] - 32s 533ms/step - loss: 0.2149 - accuracy: 0.7548 - val_loss: 0.2076 - val_accuracy: 0.7572\n",
      "Epoch 12/30\n",
      "61/61 [==============================] - 30s 501ms/step - loss: 0.2130 - accuracy: 0.7656 - val_loss: 0.1975 - val_accuracy: 0.7716\n",
      "Epoch 13/30\n",
      "61/61 [==============================] - 30s 494ms/step - loss: 0.1865 - accuracy: 0.7996 - val_loss: 0.2058 - val_accuracy: 0.8519\n",
      "Epoch 14/30\n",
      "61/61 [==============================] - 30s 499ms/step - loss: 0.1548 - accuracy: 0.8454 - val_loss: 0.1193 - val_accuracy: 0.9033\n",
      "Epoch 15/30\n",
      "61/61 [==============================] - 30s 494ms/step - loss: 0.1327 - accuracy: 0.8712 - val_loss: 0.1156 - val_accuracy: 0.8786\n",
      "Epoch 16/30\n",
      "61/61 [==============================] - 30s 492ms/step - loss: 0.1310 - accuracy: 0.8702 - val_loss: 0.0852 - val_accuracy: 0.9321\n",
      "Epoch 17/30\n",
      "61/61 [==============================] - 30s 491ms/step - loss: 0.1260 - accuracy: 0.8691 - val_loss: 0.0971 - val_accuracy: 0.9115\n",
      "Epoch 18/30\n",
      "61/61 [==============================] - 30s 495ms/step - loss: 0.1112 - accuracy: 0.8934 - val_loss: 0.0720 - val_accuracy: 0.9547\n",
      "Epoch 19/30\n",
      "61/61 [==============================] - 30s 495ms/step - loss: 0.1002 - accuracy: 0.9042 - val_loss: 0.0668 - val_accuracy: 0.9465\n",
      "Epoch 20/30\n",
      "61/61 [==============================] - 31s 504ms/step - loss: 0.0990 - accuracy: 0.9227 - val_loss: 0.0748 - val_accuracy: 0.9444\n",
      "Epoch 21/30\n",
      "61/61 [==============================] - 31s 512ms/step - loss: 0.0920 - accuracy: 0.9171 - val_loss: 0.0561 - val_accuracy: 0.9424\n",
      "Epoch 22/30\n",
      "61/61 [==============================] - 30s 499ms/step - loss: 0.0746 - accuracy: 0.9444 - val_loss: 0.0457 - val_accuracy: 0.9733\n",
      "Epoch 23/30\n",
      "61/61 [==============================] - 30s 497ms/step - loss: 0.0638 - accuracy: 0.9578 - val_loss: 0.0521 - val_accuracy: 0.9527\n",
      "Epoch 24/30\n",
      "61/61 [==============================] - 30s 501ms/step - loss: 0.0629 - accuracy: 0.9578 - val_loss: 0.0531 - val_accuracy: 0.9609\n",
      "Epoch 25/30\n",
      "61/61 [==============================] - 30s 494ms/step - loss: 0.0453 - accuracy: 0.9727 - val_loss: 0.0301 - val_accuracy: 0.9712\n",
      "Epoch 26/30\n",
      "61/61 [==============================] - 30s 495ms/step - loss: 0.0475 - accuracy: 0.9691 - val_loss: 0.0236 - val_accuracy: 0.9856\n",
      "Epoch 27/30\n",
      "61/61 [==============================] - 30s 493ms/step - loss: 0.0385 - accuracy: 0.9763 - val_loss: 0.0249 - val_accuracy: 0.9815\n",
      "Epoch 28/30\n",
      "61/61 [==============================] - 30s 495ms/step - loss: 0.0386 - accuracy: 0.9722 - val_loss: 0.0193 - val_accuracy: 0.9918\n",
      "Epoch 29/30\n",
      "61/61 [==============================] - 30s 496ms/step - loss: 0.0377 - accuracy: 0.9748 - val_loss: 0.0155 - val_accuracy: 0.9918\n",
      "Epoch 30/30\n",
      "61/61 [==============================] - 30s 496ms/step - loss: 0.0259 - accuracy: 0.9851 - val_loss: 0.0136 - val_accuracy: 0.9938\n",
      "Loss: 0.015658652409911156\n",
      "Accuracy: 0.9933110475540161\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define a function to create and compile a new model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(100, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(len(target_columns), activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Create a new model\n",
    "model = create_model()\n",
    "\n",
    "# Fit the model with the training data\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=30, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print the loss and accuracy\n",
    "print(f\"Loss: {scores[0]}\")\n",
    "print(f\"Accuracy: {scores[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 122ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1196, 1), indices imply (1196, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1654\u001b[0m, in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1649\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1650\u001b[0m         \u001b[39m# It's OK if a single block is passed as values, its placement\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m         \u001b[39m# is basically \"all items\", but if there're many, don't bother\u001b[39;00m\n\u001b[0;32m   1652\u001b[0m         \u001b[39m# converting, it's an error anyway.\u001b[39;00m\n\u001b[0;32m   1653\u001b[0m         blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m-> 1654\u001b[0m             make_block(values\u001b[39m=\u001b[39;49mblocks[\u001b[39m0\u001b[39;49m], placement\u001b[39m=\u001b[39;49m\u001b[39mslice\u001b[39;49m(\u001b[39m0\u001b[39;49m, \u001b[39mlen\u001b[39;49m(axes[\u001b[39m0\u001b[39;49m])))\n\u001b[0;32m   1655\u001b[0m         ]\n\u001b[0;32m   1657\u001b[0m mgr \u001b[39m=\u001b[39m BlockManager(blocks, axes)\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:3047\u001b[0m, in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[0;32m   3045\u001b[0m     values \u001b[39m=\u001b[39m DatetimeArray\u001b[39m.\u001b[39m_simple_new(values, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m-> 3047\u001b[0m \u001b[39mreturn\u001b[39;00m klass(values, ndim\u001b[39m=\u001b[39;49mndim, placement\u001b[39m=\u001b[39;49mplacement)\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:124\u001b[0m, in \u001b[0;36mBlock.__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_ndim \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmgr_locs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues):\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWrong number of items passed \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mplacement implies \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmgr_locs)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    127\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 1, placement implies 5",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m Y_pred_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(Y_pred, axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \n\u001b[0;32m     11\u001b[0m \u001b[39m# Convert validation observations to one hot vectors\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m Y_true \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margmax(y_test, axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m) \n\u001b[0;32m     14\u001b[0m \u001b[39m# compute the confusion matrix\u001b[39;00m\n\u001b[0;32m     15\u001b[0m confusion_mtx \u001b[39m=\u001b[39m confusion_matrix(Y_true, Y_pred_classes) \n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[39mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m-> 1216\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, method, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\numpy\\core\\fromnumeric.py:47\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m     46\u001b[0m         result \u001b[39m=\u001b[39m asarray(result)\n\u001b[1;32m---> 47\u001b[0m     result \u001b[39m=\u001b[39m wrap(result)\n\u001b[0;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\pandas\\core\\generic.py:1918\u001b[0m, in \u001b[0;36mNDFrame.__array_wrap__\u001b[1;34m(self, result, context)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m   1917\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_axes_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_AXIS_ORDERS, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1918\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(result, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49md)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\pandas\\core\\frame.py:464\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         mgr \u001b[39m=\u001b[39m init_dict({data\u001b[39m.\u001b[39mname: data}, index, columns, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    463\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m         mgr \u001b[39m=\u001b[39m init_ndarray(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    466\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, abc\u001b[39m.\u001b[39mIterable) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\pandas\\core\\internals\\construction.py:210\u001b[0m, in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     block_values \u001b[39m=\u001b[39m [values]\n\u001b[1;32m--> 210\u001b[0m \u001b[39mreturn\u001b[39;00m create_block_manager_from_blocks(block_values, [columns, index])\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1664\u001b[0m, in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1662\u001b[0m blocks \u001b[39m=\u001b[39m [\u001b[39mgetattr\u001b[39m(b, \u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m, b) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m blocks]\n\u001b[0;32m   1663\u001b[0m tot_items \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(b\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m blocks)\n\u001b[1;32m-> 1664\u001b[0m construction_error(tot_items, blocks[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m:], axes, e)\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[39mif\u001b[39;00m block_shape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEmpty data passed with indices specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1694\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (1196, 1), indices imply (1196, 5)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1) \n",
    "\n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test, axis = 1) \n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    " \n",
    "\n",
    "# plot the confusion matrix\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(Y_true, Y_pred_classes, target_names=target_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy curves for training and validation \n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "plt.title(\"Training session's progress over iterations\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Training Progress (Accuracy)')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Make predictions on the testing data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_bin \u001b[39m=\u001b[39m (model\u001b[39m.\u001b[39;49mpredict(X_test) \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Print the classification report\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, y_pred_bin, target_names\u001b[39m=\u001b[39mtarget_columns))\n",
      "File \u001b[1;32mc:\\Users\\patri\\.conda\\envs\\ml4qs_p3_8\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py:265\u001b[0m, in \u001b[0;36mKerasClassifier.predict\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    251\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the class predictions for the given test data.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \n\u001b[0;32m    253\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            Class predictions.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39mpredict(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    266\u001b[0m     \u001b[39mif\u001b[39;00m proba\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    267\u001b[0m         classes \u001b[39m=\u001b[39m proba\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "y_pred_bin = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_bin, target_names=target_columns))\n",
    "\n",
    "# Print precision, recall,and F1 score\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_bin, average='weighted', zero_division=1)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_bin, average='weighted', zero_division=1)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_bin, average='weighted', zero_division=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_18160\\125865451.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=10, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.9946417093276978 (+/- 0.013318841094162872)\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Define a function to create and compile a new model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(100, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(len(target_columns), activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Create a new model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=10, verbose=0)\n",
    "\n",
    "# Define the cross validation iterator\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Perform cross validation\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "\n",
    "# Print the cross validation score\n",
    "print(f\"Cross Validation Accuracy: {results.mean()} (+/- {results.std() * 2})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         1.         0.9835391  0.98765433\n",
      " 0.99588478 0.9834711  1.         0.99586779]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Get the weights of the first layer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m weights \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_weights()[\u001b[39m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[39m# Get the absolute values of the weights\u001b[39;00m\n\u001b[0;32m      5\u001b[0m abs_weights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(weights)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'layers'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4qs_p3_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
